{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, Y = make_classification(n_samples=1000, n_classes=2, n_features=5, n_redundant=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 5), (1000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 5), (800,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest_Neighbors\", \"Linear_SVM\", \"Polynomial_SVM\", \"RBF_SVM\", \"Gaussian_Process\",\n",
    "         \"Gradient_Boosting\", \"Decision_Tree\", \"Extra_Trees\", \"Random_Forest\", \"Neural_Net\", \"AdaBoost\",\n",
    "         \"Naive_Bayes\", \"QDA\", \"SGD\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(kernel=\"poly\", degree=3, C=0.025),\n",
    "    SVC(kernel=\"rbf\", C=1, gamma=2),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    ExtraTreesClassifier(n_estimators=10, min_samples_split=2),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(n_estimators=100),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    SGDClassifier(loss=\"hinge\", penalty=\"l2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    score = clf.score(X_test, Y_test)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive_Bayes</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian_Process</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neural_Net</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear_SVM</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extra_Trees</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosting</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nearest_Neighbors</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial_SVM</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBF_SVM</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  score\n",
       "11        Naive_Bayes  0.895\n",
       "4    Gaussian_Process  0.890\n",
       "8       Random_Forest  0.890\n",
       "6       Decision_Tree  0.885\n",
       "9          Neural_Net  0.885\n",
       "1          Linear_SVM  0.880\n",
       "12                QDA  0.880\n",
       "7         Extra_Trees  0.865\n",
       "5   Gradient_Boosting  0.860\n",
       "0   Nearest_Neighbors  0.855\n",
       "10           AdaBoost  0.845\n",
       "13                SGD  0.835\n",
       "2      Polynomial_SVM  0.830\n",
       "3             RBF_SVM  0.805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "df['name'] = names\n",
    "df['score'] = scores\n",
    "df.sort_values(by=[\"score\"], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4d6a9_row0_col1 {\n",
       "  background-color: #008000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row1_col1, #T_4d6a9_row2_col1 {\n",
       "  background-color: #0d860d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row3_col1, #T_4d6a9_row4_col1 {\n",
       "  background-color: #1a8d1a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row5_col1, #T_4d6a9_row6_col1 {\n",
       "  background-color: #279327;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row7_col1 {\n",
       "  background-color: #4ea64e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row8_col1 {\n",
       "  background-color: #5bad5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row9_col1 {\n",
       "  background-color: #68b368;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4d6a9_row10_col1 {\n",
       "  background-color: #83c083;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4d6a9_row11_col1 {\n",
       "  background-color: #9ccd9c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4d6a9_row12_col1 {\n",
       "  background-color: #a9d3a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4d6a9_row13_col1 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4d6a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4d6a9_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_4d6a9_level0_col1\" class=\"col_heading level0 col1\" >score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row0\" class=\"row_heading level0 row0\" >11</th>\n",
       "      <td id=\"T_4d6a9_row0_col0\" class=\"data row0 col0\" >Naive_Bayes</td>\n",
       "      <td id=\"T_4d6a9_row0_col1\" class=\"data row0 col1\" >0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_4d6a9_row1_col0\" class=\"data row1 col0\" >Gaussian_Process</td>\n",
       "      <td id=\"T_4d6a9_row1_col1\" class=\"data row1 col1\" >0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row2\" class=\"row_heading level0 row2\" >8</th>\n",
       "      <td id=\"T_4d6a9_row2_col0\" class=\"data row2 col0\" >Random_Forest</td>\n",
       "      <td id=\"T_4d6a9_row2_col1\" class=\"data row2 col1\" >0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row3\" class=\"row_heading level0 row3\" >6</th>\n",
       "      <td id=\"T_4d6a9_row3_col0\" class=\"data row3 col0\" >Decision_Tree</td>\n",
       "      <td id=\"T_4d6a9_row3_col1\" class=\"data row3 col1\" >0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row4\" class=\"row_heading level0 row4\" >9</th>\n",
       "      <td id=\"T_4d6a9_row4_col0\" class=\"data row4 col0\" >Neural_Net</td>\n",
       "      <td id=\"T_4d6a9_row4_col1\" class=\"data row4 col1\" >0.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row5\" class=\"row_heading level0 row5\" >1</th>\n",
       "      <td id=\"T_4d6a9_row5_col0\" class=\"data row5 col0\" >Linear_SVM</td>\n",
       "      <td id=\"T_4d6a9_row5_col1\" class=\"data row5 col1\" >0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row6\" class=\"row_heading level0 row6\" >12</th>\n",
       "      <td id=\"T_4d6a9_row6_col0\" class=\"data row6 col0\" >QDA</td>\n",
       "      <td id=\"T_4d6a9_row6_col1\" class=\"data row6 col1\" >0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4d6a9_row7_col0\" class=\"data row7 col0\" >Extra_Trees</td>\n",
       "      <td id=\"T_4d6a9_row7_col1\" class=\"data row7 col1\" >0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row8\" class=\"row_heading level0 row8\" >5</th>\n",
       "      <td id=\"T_4d6a9_row8_col0\" class=\"data row8 col0\" >Gradient_Boosting</td>\n",
       "      <td id=\"T_4d6a9_row8_col1\" class=\"data row8 col1\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row9\" class=\"row_heading level0 row9\" >0</th>\n",
       "      <td id=\"T_4d6a9_row9_col0\" class=\"data row9 col0\" >Nearest_Neighbors</td>\n",
       "      <td id=\"T_4d6a9_row9_col1\" class=\"data row9 col1\" >0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4d6a9_row10_col0\" class=\"data row10 col0\" >AdaBoost</td>\n",
       "      <td id=\"T_4d6a9_row10_col1\" class=\"data row10 col1\" >0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row11\" class=\"row_heading level0 row11\" >13</th>\n",
       "      <td id=\"T_4d6a9_row11_col0\" class=\"data row11 col0\" >SGD</td>\n",
       "      <td id=\"T_4d6a9_row11_col1\" class=\"data row11 col1\" >0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row12\" class=\"row_heading level0 row12\" >2</th>\n",
       "      <td id=\"T_4d6a9_row12_col0\" class=\"data row12 col0\" >Polynomial_SVM</td>\n",
       "      <td id=\"T_4d6a9_row12_col1\" class=\"data row12 col1\" >0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d6a9_level0_row13\" class=\"row_heading level0 row13\" >3</th>\n",
       "      <td id=\"T_4d6a9_row13_col0\" class=\"data row13 col0\" >RBF_SVM</td>\n",
       "      <td id=\"T_4d6a9_row13_col1\" class=\"data row13 col1\" >0.805000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fddad66360>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "s = df.style.background_gradient(cmap=cm)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.barplot(y=\"name\", x=\"score\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Создаём X и y\n",
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "# Разбиение на обучающий и тестовый наборы - TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Масштабирование данных (SCALE)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ElasticNet in module sklearn.linear_model._coordinate_descent:\n",
      "\n",
      "class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      " |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |\n",
      " |  Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |\n",
      " |  Minimizes the objective function::\n",
      " |\n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |\n",
      " |  If you are interested in controlling the L1 and L2 penalty\n",
      " |  separately, keep in mind that this is equivalent to::\n",
      " |\n",
      " |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      " |\n",
      " |  where::\n",
      " |\n",
      " |          alpha = a + b and l1_ratio = a / (a + b)\n",
      " |\n",
      " |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      " |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      " |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      " |  unless you supply your own sequence of alpha.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, default=1.0\n",
      " |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      " |      See the notes for the exact mathematical meaning of this\n",
      " |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      " |      solved by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |\n",
      " |  l1_ratio : float, default=0.5\n",
      " |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      " |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      " |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |\n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether the intercept should be estimated or not. If ``False``, the\n",
      " |      data is assumed to be already centered.\n",
      " |\n",
      " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. The Gram matrix can also be passed as argument.\n",
      " |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      " |\n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations.\n",
      " |\n",
      " |  copy_X : bool, default=True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |\n",
      " |  tol : float, default=1e-4\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``, see Notes below.\n",
      " |\n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |\n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |\n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update. Used when ``selection`` == 'random'.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |\n",
      " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Parameter vector (w in the cost function formula).\n",
      " |\n",
      " |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      " |      Sparse representation of the `coef_`.\n",
      " |\n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function.\n",
      " |\n",
      " |  n_iter_ : list of int\n",
      " |      Number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |\n",
      " |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      " |      Given param alpha, the dual gaps at the end of the optimization,\n",
      " |      same shape as each observation of y.\n",
      " |\n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |\n",
      " |      .. versionadded:: 1.0\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  ElasticNetCV : Elastic net model with best model selection by\n",
      " |      cross-validation.\n",
      " |  SGDRegressor : Implements elastic net regression with incremental training.\n",
      " |  SGDClassifier : Implements logistic regression with elastic net penalty\n",
      " |      (``SGDClassifier(loss=\"log_loss\", penalty=\"elasticnet\")``).\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |\n",
      " |  The precise stopping criteria based on `tol` are the following: First, check that\n",
      " |  that maximum coordinate update, i.e. :math:`\\max_j |w_j^{new} - w_j^{old}|`\n",
      " |  is smaller than `tol` times the maximum absolute coefficient, :math:`\\max_j |w_j|`.\n",
      " |  If so, then additionally check whether the dual gap is smaller than `tol` times\n",
      " |  :math:`||y||_2^2 / n_{      ext{samples}}`.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import ElasticNet\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |\n",
      " |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      " |  >>> regr = ElasticNet(random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  ElasticNet(random_state=0)\n",
      " |  >>> print(regr.coef_)\n",
      " |  [18.83816048 64.55968825]\n",
      " |  >>> print(regr.intercept_)\n",
      " |  1.451...\n",
      " |  >>> print(regr.predict([[0, 0]]))\n",
      " |  [1.451...]\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      ElasticNet\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      " |          Data.\n",
      " |\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary.\n",
      " |\n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. Internally, the `sample_weight` vector will be\n",
      " |          rescaled to sum to `n_samples`.\n",
      " |\n",
      " |          .. versionadded:: 0.23\n",
      " |\n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |\n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |\n",
      " |  set_fit_request(self: sklearn.linear_model._coordinate_descent.ElasticNet, *, check_input: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNet\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      check_input : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``check_input`` parameter in ``fit``.\n",
      " |\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_score_request(self: sklearn.linear_model._coordinate_descent.ElasticNet, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._coordinate_descent.ElasticNet\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent.\n",
      " |\n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |\n",
      " |      For mono-output tasks it is::\n",
      " |\n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |\n",
      " |      For multi-output tasks it is::\n",
      " |\n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |\n",
      " |      Where::\n",
      " |\n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |\n",
      " |      i.e. the sum of norm of each row.\n",
      " |\n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |\n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      " |          Target values.\n",
      " |\n",
      " |      l1_ratio : float, default=0.5\n",
      " |          Number between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      " |\n",
      " |      eps : float, default=1e-3\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``.\n",
      " |\n",
      " |      n_alphas : int, default=100\n",
      " |          Number of alphas along the regularization path.\n",
      " |\n",
      " |      alphas : ndarray, default=None\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically.\n",
      " |\n",
      " |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |\n",
      " |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |\n",
      " |      copy_X : bool, default=True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |\n",
      " |      coef_init : ndarray of shape (n_features, ), default=None\n",
      " |          The initial values of the coefficients.\n",
      " |\n",
      " |      verbose : bool or int, default=False\n",
      " |          Amount of verbosity.\n",
      " |\n",
      " |      return_n_iter : bool, default=False\n",
      " |          Whether to return the number of iterations or not.\n",
      " |\n",
      " |      positive : bool, default=False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |\n",
      " |      check_input : bool, default=True\n",
      " |          If set to False, the input validation checks are skipped (including the\n",
      " |          Gram matrix when provided). It is assumed that they are handled\n",
      " |          by the caller.\n",
      " |\n",
      " |      **params : kwargs\n",
      " |          Keyword arguments passed to the coordinate descent solver.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : ndarray of shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |\n",
      " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |\n",
      " |      dual_gaps : ndarray of shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |\n",
      " |      n_iters : list of int\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      " |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      " |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  sparse_coef_\n",
      " |      Sparse representation of the fitted `coef_`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |\n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |\n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |\n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |\n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |\n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |\n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |\n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ElasticNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_model = ElasticNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,1,5,10,50,100],\n",
    "              'l1_ratio':[.1, .5, .7, .9, .95, .99, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число verbose выбирайте сами\n",
    "grid_model = GridSearchCV(estimator=base_elastic_model,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=5,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.1, l1_ratio=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.387342642087474"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
